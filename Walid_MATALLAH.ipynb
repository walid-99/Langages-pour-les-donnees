{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636c4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation du fichier csv\n",
    "import pandas as pd\n",
    "import random\n",
    "df=pd.read_csv(\"opinions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad88229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supprimer la colonne review:\n",
    "df = df.drop('review', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0bfae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Nombre de valeurs vides\n",
      "ID                             0\n",
      "score                          3\n",
      "opinion                        0\n"
     ]
    }
   ],
   "source": [
    "#affichage de nombre de valeurs vides par colonne:\n",
    "missing_values = df.isnull().sum()\n",
    "missing_df = pd.DataFrame(missing_values, columns=['Nombre de valeurs vides'])\n",
    "print(missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b514cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False]\n",
      " [False False False]\n",
      " [False False False]\n",
      " ...\n",
      " [False False False]\n",
      " [False False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "#matrice des valeurs vides:\n",
    "import numpy as np\n",
    "missing_matrix = df.isnull().to_numpy()\n",
    "print(missing_matrix)\n",
    "np.savetxt('missing_matrix.txt', missing_matrix, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3ff147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion</th>\n",
       "      <th>ville</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3870</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3204</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1265</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>852</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>2163</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>2488</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>868</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4084 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   score   opinion ville\n",
       "0     3870  0.5000  positive     5\n",
       "1       62  0.2794  positive     2\n",
       "2      487  0.1827  positive     2\n",
       "3     3204  0.3682  positive     2\n",
       "4     1265  0.2333  positive     2\n",
       "...    ...     ...       ...   ...\n",
       "4079   852  0.4571  positive     4\n",
       "4080  2163  0.0000   neutral     1\n",
       "4081  2488  0.0000   neutral     3\n",
       "4082   651  0.0000   neutral     5\n",
       "4083   868 -0.3125  negative     2\n",
       "\n",
       "[4084 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#création de la colonne ville:\n",
    "villes = [random.choice(['1', '2', '3', '4', '5']) for _ in range(len(df))]\n",
    "df['ville']=villes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a1fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la moyenne de la colonne\n",
    "moyenne = df[\"score\"].mean()\n",
    "\n",
    "# Remplacer les valeurs manquantes de la colonne par la moyenne\n",
    "df[\"score\"].fillna(moyenne, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7d049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID         0\n",
      "score      0\n",
      "opinion    0\n",
      "ville      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cd75f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID   score   opinion ville\n",
      "0     3870  0.5000  positive     4\n",
      "1       62  0.2794  positive     5\n",
      "2      487  0.1827  positive     1\n",
      "3     3204  0.3682  positive     1\n",
      "4     1265  0.2333  positive     3\n",
      "...    ...     ...       ...   ...\n",
      "4079   852  0.4571  positive     3\n",
      "4080  2163  0.0000   neutral     4\n",
      "4081  2488  0.0000   neutral     3\n",
      "4082   651  0.0000   neutral     5\n",
      "4083   868 -0.3125  negative     5\n",
      "\n",
      "[4084 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Sélectionner uniquement la colonne \"score\" pour l'imputation\n",
    "score_column = df['score'].values.reshape(-1, 1)\n",
    "\n",
    "# Appliquer l'imputation KNN aux valeurs manquantes de la colonne \"score\"\n",
    "score_imputed = imputer.fit_transform(score_column)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans la colonne \"score\" par les valeurs imputées\n",
    "df['score'] = score_imputed\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b920a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID   score   opinion ville\n",
      "0     3870  0.5000  positive     5\n",
      "1       62  0.2794  positive     2\n",
      "2      487  0.1827  positive     2\n",
      "3     3204  0.3682  positive     2\n",
      "4     1265  0.2333  positive     2\n",
      "...    ...     ...       ...   ...\n",
      "4079   852  0.4571  positive     4\n",
      "4080  2163  0.0000   neutral     1\n",
      "4081  2488  0.0000   neutral     3\n",
      "4082   651  0.0000   neutral     5\n",
      "4083   868 -0.3125  negative     2\n",
      "\n",
      "[4084 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[0.      2.5515  2.79325 ... 2.125   1.25    2.25   ]\n",
      " [2.5515  0.      2.74175 ... 2.0735  0.6985  2.8015 ]\n",
      " [2.79325 2.74175 0.      ... 1.83175 0.45675 3.04325]\n",
      " ...\n",
      " [2.125   2.0735  1.83175 ... 0.      0.875   2.375  ]\n",
      " [1.25    0.6985  0.45675 ... 0.875   0.      1.5    ]\n",
      " [2.25    2.8015  3.04325 ... 2.375   1.5     0.     ]]\n",
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "def similarity(row1, row2):\n",
    "    # Calculer la similarité selon le critère du score\n",
    "    score_similarity = np.abs(row1['score'] - row2['score']) *2.5\n",
    "\n",
    "    # Calculer la similarité selon le critère de l'opinion\n",
    "    opinion_similarity = 0\n",
    "    if row1['opinion'] == row2['opinion']:\n",
    "        opinion_similarity = 2\n",
    "    elif (row1['opinion'] == 'neutral' and row2['opinion'] == 'postive') or (row1['opinion'] == 'neutral' and row2['opinion'] == 'negative'):\n",
    "        opinion_similarity = 1\n",
    "    \n",
    "        \n",
    "\n",
    "    # Calculer la similarité selon le critère de la ville\n",
    "    ville_similarity = 0\n",
    "    if row1['ville'] == row2['ville']:\n",
    "        ville_similarity = 0.5\n",
    "\n",
    "    # Calculer la similarité totale\n",
    "    total_similarity = score_similarity + opinion_similarity + ville_similarity\n",
    "\n",
    "    return total_similarity\n",
    "\n",
    "# Fonction pour calculer la matrice de similarité entre les clients\n",
    "def similarity_matrix(data):\n",
    "    # Initialiser la matrice de similarité\n",
    "    n = data.shape[0]\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "    # Calculer la similarité entre chaque paire de clients\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 0\n",
    "            else:\n",
    "                similarity_matrix[i, j] = similarity(data.iloc[i], data.iloc[j])\n",
    "                similarity_matrix[j, i] = similarity_matrix[i, j]\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Calculer la matrice de similarité et copie dans un fichier CSV\n",
    "df_100 = df.head(200)\n",
    "# df_100=df\n",
    "print(type(df_100))\n",
    "\n",
    "similarity_matrix = similarity_matrix(df_100)\n",
    "print(similarity_matrix)\n",
    "np.savetxt('premierematrice_200.csv', similarity_matrix, delimiter='\\t')\n",
    "print(similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d80d1",
   "metadata": {},
   "source": [
    "# Partie2:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d182c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3870</td>\n",
       "      <td>able play youtube alexa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>+A35able recognize indian accent really well d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>absolute smart device amazon connect external ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3204</td>\n",
       "      <td>absolutely amaze new member family control hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1265</td>\n",
       "      <td>absolutely amaze previously sceptical invest m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                             review\n",
       "0  3870                            able play youtube alexa\n",
       "1    62  +A35able recognize indian accent really well d...\n",
       "2   487  absolute smart device amazon connect external ...\n",
       "3  3204  absolutely amaze new member family control hom...\n",
       "4  1265  absolutely amaze previously sceptical invest m..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importation du fichier csv et suppression des colonnes score et opinions:\n",
    "import pandas as pd\n",
    "import random\n",
    "col=pd.read_csv(\"opinions.csv\")\n",
    "col = col.drop('score', axis=1)\n",
    "col = col.drop('opinion', axis=1)\n",
    "col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d72c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID                                             review\n",
      "0     3870                            able play youtube alexa\n",
      "1       62  aable recognize indian accent really well drop...\n",
      "2      487  absolute smart device amazon connect external ...\n",
      "3     3204  absolutely amaze new member family control hom...\n",
      "4     1265  absolutely amaze previously sceptical invest m...\n",
      "...    ...                                                ...\n",
      "4079   852  yo yo yo love go if want one smart speaker val...\n",
      "4080  2163                                      youtube music\n",
      "4081  2488  youtube support nahi kartasong recognise achha...\n",
      "4082   651  yup proscontrols wipro light amazinglysony bra...\n",
      "4083   868  zero integration capabilities fire tv devices ...\n",
      "\n",
      "[4084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def nettoyer_texte(texte):\n",
    "    texte = re.sub(r'[^\\w\\s]', '', texte)  # Supprimer les caractères spéciaux\n",
    "    texte = re.sub(r'[\\d+]', '', texte)  # Supprimer les numéros\n",
    "    texte = texte.lower()  # Mettre tout en minuscules\n",
    "    return texte\n",
    "\n",
    "\n",
    "# Application de la fonction de nettoyage à la colonne \"review\"\n",
    "col['review'] = col['review'].apply(nettoyer_texte)\n",
    "\n",
    "# Afficher le DataFrame mis à jour\n",
    "print(col)\n",
    "col.to_csv('data_version2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d18a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('vader_lexicon')  # Téléchargement du lexique de sentiment\n",
    "nltk.download('wordnet')  # Téléchargement du corpus WordNet pour la lemmatisation\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialisation de l'analyseur de sentiment et du lemmatiseur\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fonction pour déterminer l'opinion en fonction du score\n",
    "def get_opinion(score):\n",
    "    if score > 0.1:\n",
    "        return 'positive'\n",
    "    elif score < -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Fonction pour appliquer la lemmatisation à un texte donné\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split()])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Fonction pour obtenir la partie du discours WordNet correspondante\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Chargement du DataFrame\n",
    "df = pd.read_csv('data_version2.csv')  # Remplacez 'your_dataframe.csv' par le chemin vers votre DataFrame\n",
    "\n",
    "# Application de la lemmatisation à la colonne 'review'\n",
    "df['lemmatized_review'] = df['review'].apply(lemmatize_text)\n",
    "\n",
    "# Application de l'analyse de sentiment à la colonne 'lemmatized_review' pour obtenir le score et l'opinion\n",
    "df['score'] = df['lemmatized_review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "df['opinion'] = df['score'].apply(get_opinion)\n",
    "\n",
    "# Enregistrement du DataFrame mis à jour avec le score de sentiment et l'opinion\n",
    "df.to_csv('updated_dataframe.csv', index=False)  # Remplacez 'updated_dataframe.csv' par le chemin et le nom de fichier souhaités\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8e462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1733  58    3400  2855  75    517   713   2536  3194  3670  ...  1387  \\\n",
      "1733   4.5   2.0   0.0   2.0   2.0   2.0   0.0   2.0   2.0   2.0  ...   2.0   \n",
      "58     2.0   4.5   0.0   2.0   2.0   2.0   0.0   2.0   2.0   2.0  ...   2.0   \n",
      "3400   0.0   0.0   4.5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2855   2.0   2.0   0.0   4.5   2.0   2.0   0.0   2.0   2.0   2.0  ...   2.0   \n",
      "75     2.0   2.0   0.0   2.0   4.5   2.0   0.0   2.0   2.0   2.0  ...   2.0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "4008   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0  ...   0.0   \n",
      "790    0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0  ...   0.0   \n",
      "1752   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0  ...   0.0   \n",
      "2664   0.0   0.0   4.5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1339   2.0   2.0   0.0   2.0   2.0   2.0   0.0   2.0   2.0   2.0  ...   4.5   \n",
      "\n",
      "      1638  1225  3768  481   4008  790   1752  2664  1339  \n",
      "1733   2.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   2.0  \n",
      "58     2.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   2.0  \n",
      "3400   0.0   4.5   0.0   0.0   0.0   0.0   0.0   4.5   0.0  \n",
      "2855   2.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   2.0  \n",
      "75     2.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   2.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "4008   0.0   0.0   0.0   0.0   4.5   2.0   2.0   0.0   0.0  \n",
      "790    0.0   0.0   0.0   0.0   2.0   4.5   2.0   0.0   0.0  \n",
      "1752   0.0   0.0   0.0   0.0   2.0   2.0   4.5   0.0   0.0  \n",
      "2664   0.0   4.5   0.0   0.0   0.0   0.0   0.0   4.5   0.0  \n",
      "1339   2.0   0.0   2.0   2.0   0.0   0.0   0.0   0.0   4.5  \n",
      "\n",
      "[100 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "#calcule de la matrice de similarité globale du la data_version2:\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "df1 = pd.read_csv('updated_dataframe.csv')\n",
    "# Sélectionner un petit échantillon de votre dataframe\n",
    "sample_size = 100  # Spécifiez la taille de l'échantillon souhaitée\n",
    "df_sample = df1.sample(n=sample_size)\n",
    "\n",
    "# Calculer la similarité basée sur les colonnes \"score\" et \"opinion\"\n",
    "def calculate_similarity(row1, row2):\n",
    "    score_sim = 2.5 if row1['score'] == row2['score'] else 0\n",
    "    opinion_sim = 2 if row1['opinion'] == row2['opinion'] else 0\n",
    "    if row1['opinion'] == 'Neutral' or row2['opinion'] == 'Neutral':\n",
    "        opinion_sim = 1\n",
    "    \n",
    "    total_sim = score_sim + opinion_sim\n",
    "    return total_sim\n",
    "\n",
    "# Créer une matrice de similarité\n",
    "def create_similarity_matrix(df):\n",
    "    index_combinations = list(product(df.index, repeat=2))\n",
    "    similarity_scores = [calculate_similarity(df.loc[i], df.loc[j]) for i, j in index_combinations]\n",
    "    \n",
    "    similarity_matrix = pd.DataFrame(index=df.index, columns=df.index, \n",
    "                                     data=np.array(similarity_scores).reshape(len(df), len(df)))\n",
    "    return similarity_matrix\n",
    "\n",
    "# Obtenir la matrice de similarité pour l'échantillon sélectionné\n",
    "similarity_matrix = create_similarity_matrix(df_sample)\n",
    "\n",
    "# Afficher la matrice de similarité\n",
    "print(similarity_matrix)\n",
    "np.savetxt('deuxièmematrice_100.csv', similarity_matrix, delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd802ee2",
   "metadata": {},
   "source": [
    "# pour aller plus loin dans la partie 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Définition de la classe ReviewDataset qui hérite de la classe Dataset\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Chargement des données\n",
    "df_with_labels = pd.read_csv('opinions.csv').sample(frac=0.1)  # utiliser une fraction des données\n",
    "df_without_labels = pd.read_csv('clean.csv').sample(frac=0.1)  # utiliser une fraction des données\n",
    "\n",
    "# Initialisation du tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Tokenization du texte\n",
    "encodings = tokenizer(df_with_labels['review'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Encodage des labels avec LabelEncoder\n",
    "label_encoder_opinion = LabelEncoder()\n",
    "df_with_labels['opinion'] = label_encoder_opinion.fit_transform(df_with_labels['opinion'])\n",
    "\n",
    "label_encoder_score = LabelEncoder()\n",
    "df_with_labels['score'] = label_encoder_score.fit_transform(df_with_labels['score'])\n",
    "\n",
    "# Encodage one-hot des labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "labels_opinion_onehot = one_hot_encoder.fit_transform(df_with_labels['opinion'].values.reshape(-1, 1))\n",
    "labels_score_onehot = one_hot_encoder.transform(df_with_labels['score'].values.reshape(-1, 1))\n",
    "\n",
    "# Création des jeux de données\n",
    "dataset_opinion = ReviewDataset(encodings, labels_opinion_onehot)\n",
    "dataset_score = ReviewDataset(encodings, labels_score_onehot)\n",
    "\n",
    "# Initialisation des modèles\n",
    "model_opinion = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)\n",
    "model_score = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)\n",
    "\n",
    "# Initialisation des arguments d'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Initialisation des entraîneurs\n",
    "trainer_opinion = Trainer(\n",
    "    model=model_opinion,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_opinion,\n",
    ")\n",
    "\n",
    "trainer_score = Trainer(\n",
    "    model=model_score,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_score,\n",
    ")\n",
    "\n",
    "# Entraînement des modèles\n",
    "trainer_opinion.train()\n",
    "trainer_score.train()\n",
    "\n",
    "# Tokenization et prédiction\n",
    "new_reviews = df_without_labels['review'].tolist()\n",
    "new_encodings = tokenizer(new_reviews, truncation=True, padding=True)\n",
    "\n",
    "# Prédiction des opinions\n",
    "new_dataset_opinion = ReviewDataset(new_encodings, labels=[0]*len(new_reviews))\n",
    "preds_opinion = trainer_opinion.predict(new_dataset_opinion)\n",
    "df_without_labels['predicted_opinion'] = label_encoder_opinion.inverse_transform(preds_opinion.predictions.argmax(axis=1))\n",
    "\n",
    "# Prédiction des scores\n",
    "new_dataset_score = ReviewDataset(new_encodings, labels=[0]*len(new_reviews))\n",
    "preds_score = trainer_score.predict(new_dataset_score)\n",
    "df_without_labels['predicted_score'] = label_encoder_score.inverse_transform(preds_score.predictions.argmax(axis=1))\n",
    "\n",
    "# Sauvegarde des prédictions\n",
    "df_without_labels.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
